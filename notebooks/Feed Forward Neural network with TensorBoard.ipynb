{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "## Feed forward Neural Networks - with variable scopes and summaries\n",
    "---\n",
    "\n",
    "Lets load the MNIST dataset first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports\n",
    "import time\n",
    "from IPython import display\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image, ImageOps\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Read the mnist dataset\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_features = 784\n",
    "num_classes = 10\n",
    "log_path = \"../logs/ffnn\"\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "training_epochs = 5\n",
    "\n",
    "# Layer sizes\n",
    "layer_1_size = 256\n",
    "layer_2_size = 128\n",
    "\n",
    "# Create placeholders\n",
    "x = tf.placeholder(tf.float32, shape=(None, 784))\n",
    "y = tf.placeholder(tf.float32, shape=(None, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create a function to get all the statistics of a variable and create summaries. This will be used to write summaries for things like weight vectors and biases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Code from - https://www.tensorflow.org/get_started/summaries_and_tensorboard\n",
    "def variable_summaries(var):\n",
    "    # Attach a scope for the summary\n",
    "    with tf.name_scope(\"summaries\"):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        \n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        \n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create a function for a neural network layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):\n",
    "    # Scope the entire layer with its name\n",
    "    with tf.name_scope(layer_name):\n",
    "        # Scope for the weights\n",
    "        with tf.name_scope(\"weights\"):\n",
    "            weights = tf.Variable(tf.truncated_normal([input_dim, output_dim], stddev=0.1))\n",
    "            variable_summaries(weights)\n",
    "        # Scope for biases\n",
    "        with tf.name_scope(\"biases\"):\n",
    "            biases = tf.Variable(tf.constant(0.1, shape=([output_dim])))\n",
    "            variable_summaries(biases)\n",
    "        # Scope for preactivations\n",
    "        with tf.name_scope(\"preacts\"):\n",
    "            preacts = tf.add(tf.matmul(input_tensor, weights), biases)\n",
    "            tf.summary.histogram('pre_activations', preacts)\n",
    "        # Scope for activations \n",
    "        with tf.name_scope(\"activations\"):\n",
    "            activations = act(preacts, name=\"activation\")\n",
    "            tf.summary.histogram('activations', activations)\n",
    "            \n",
    "        return activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build the network\n",
    "hidden1 = nn_layer(x, num_features, layer_1_size, \"layer1\")\n",
    "hidden2 = nn_layer(hidden1, layer_1_size, layer_2_size, \"layer2\")\n",
    "\n",
    "# Final layer - Use tf.identity to make sure there are no activations\n",
    "logits = nn_layer(hidden2, layer_2_size, num_classes, \"softmax\", act=tf.identity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Compute the Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Compute the cross entropy\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    deltas = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    with tf.name_scope('total'):\n",
    "        cross_entropy_loss = tf.reduce_mean(deltas)\n",
    "        tf.summary.scalar('cross_entropy', cross_entropy_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Define the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('train_step'):\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Compute the accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"evaluation\"):\n",
    "    with tf.name_scope(\"correct_prediction\"):\n",
    "        correct_predictions = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now lets run our graph as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/5. Batch: 500/550. Current loss: 0.19516. Train Accuracy: 0.94\n",
      "Test Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Initializing global variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Merge all the summaries\n",
    "summaries = tf.summary.merge_all()\n",
    "\n",
    "# Create a session to run the graph\n",
    "with tf.Session() as sess:\n",
    "    # Run initialization\n",
    "    sess.run(init)\n",
    "    \n",
    "    summary_writer = tf.summary.FileWriter(log_path, sess.graph)\n",
    "    \n",
    "    # For the set number of epochs\n",
    "    for epoch in range(training_epochs):\n",
    "        \n",
    "        # Compute the total number of batches\n",
    "        num_batches = int(mnist.train.num_examples/batch_size)\n",
    "        \n",
    "        # Iterate over all the examples (1 epoch)\n",
    "        for batch in range(num_batches):\n",
    "            \n",
    "            # Get a batch of examples\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "\n",
    "            # Now run the session \n",
    "            curr_loss, cur_accuracy, _, summary = sess.run([cross_entropy_loss, accuracy, train_step, summaries], \n",
    "                                                            feed_dict={x: batch_xs, y: batch_ys})\n",
    "            \n",
    "            \n",
    "            if batch % 50 == 0:\n",
    "                # Write the log after each iteration\n",
    "                summary_writer.add_summary(summary, epoch * num_batches + batch)\n",
    "                display.clear_output(wait=True)\n",
    "#                 time.sleep(0.05)\n",
    "                # Print the loss\n",
    "                print(\"Epoch: %d/%d. Batch: %d/%d. Current loss: %.5f. Train Accuracy: %.2f\"\n",
    "                      %(epoch, training_epochs, batch, num_batches, curr_loss, cur_accuracy))\n",
    "\n",
    "            \n",
    "    # Run the session to compute the value and print it\n",
    "    test_accuracy = sess.run(accuracy,\n",
    "                                       feed_dict={x: mnist.test.images, \n",
    "                                                  y: mnist.test.labels})\n",
    "    print(\"Test Accuracy: %.2f\"%test_accuracy)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
